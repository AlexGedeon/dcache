package org.dcache.pool.repository.meta.db;

import com.google.common.base.Stopwatch;
import com.sleepycat.collections.StoredMap;
import com.sleepycat.je.DatabaseException;
import com.sleepycat.je.EnvironmentConfig;
import com.sleepycat.je.EnvironmentFailureException;
import com.sleepycat.je.OperationFailureException;
import com.sleepycat.je.Transaction;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.NoSuchFileException;
import java.nio.file.Path;
import java.nio.file.attribute.BasicFileAttributeView;
import java.nio.file.attribute.BasicFileAttributes;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.stream.Collectors;

import diskCacheV111.util.CacheException;
import diskCacheV111.util.DiskErrorCacheException;
import diskCacheV111.util.PnfsId;
import diskCacheV111.vehicles.StorageInfo;

import dmg.cells.nucleus.EnvironmentAware;

import org.dcache.pool.repository.DuplicateEntryException;
import org.dcache.pool.repository.FileStore;
import org.dcache.pool.repository.MetaDataRecord;
import org.dcache.pool.repository.MetaDataStore;
import org.dcache.pool.repository.Repository;
import org.dcache.util.ConfigurationMapFactoryBean;

import static java.util.Arrays.asList;

/**
 * BerkeleyDB based MetaDataRepository implementation.
 *
 * The database is stored in a subdirectory of the pool directory
 * called 'meta'.
 *
 * The cache repository entries generated by this store fetch storage
 * info from the database on demand and caches them using a
 * SoftReference.
 */
public class BerkeleyDBMetaDataRepository
    implements MetaDataStore, EnvironmentAware
{
    private static final Logger _log =
        LoggerFactory.getLogger(BerkeleyDBMetaDataRepository.class);

    private static final String DIRECTORY_NAME = "meta";

    private static final String REMOVING_REDUNDANT_META_DATA =
            "Removing redundant meta data for %s.";

    /**
     * The file store for which we hold the meta data.
     */
    private final FileStore _fileStore;
    private final boolean _readOnly;

    /**
     * The BerkeleyDB database to use.
     */
    private MetaDataRepositoryDatabase _database;

    /**
     * The BerkeleyDB database to use.
     */
    private MetaDataRepositoryViews _views;

    /**
     * Directory containing the database.
     */
    private final Path _dir;

    /**
     * Berkeley DB configuration properties.
     */
    private final Properties _properties = new Properties();

    /**
     * Opens a BerkeleyDB based meta data repository. If the database
     * does not exist yet, then it is created. If the 'meta' directory
     * does not exist, it is created.
     */
    public BerkeleyDBMetaDataRepository(FileStore fileStore, Path directory)
            throws IOException, DatabaseException, CacheException
    {
        this(fileStore, directory, false);
    }

    public BerkeleyDBMetaDataRepository(FileStore fileStore, Path directory, boolean readOnly)
            throws IOException, DatabaseException
    {
        _fileStore = fileStore;
        _readOnly = readOnly;
        _dir = directory.resolve(DIRECTORY_NAME);

        if (!Files.exists(_dir)) {
            Files.createDirectory(_dir);
        } else if (!Files.isDirectory(_dir)) {
            throw new FileNotFoundException("No such directory: " + _dir);
        }
    }

    @Override
    public void setEnvironment(Map<String, Object> environment)
    {
        ConfigurationMapFactoryBean factory = new ConfigurationMapFactoryBean();
        factory.setEnvironment(environment);
        factory.setPrefix("pool.plugins.meta.db");
        factory.buildMap();
        _properties.clear();
        _properties.putAll(factory.getObject());
    }

    @Override
    public void init() throws CacheException
    {
        try {
            _database = new MetaDataRepositoryDatabase(_properties, _dir.toFile(), _readOnly);
            _views = new MetaDataRepositoryViews(_database);
        } catch (EnvironmentFailureException e) {
            throw new CacheException(CacheException.PANIC, "Failed to open Berkeley DB database. When upgrading to " +
                                                           "dCache 2.6, it may be necessary to run the /usr/sbin/dcache-pool-meta-preupgrade utility " +
                                                           "before starting the pool. If that does not resolve the problem, you should contact " +
                                                           "support@dcache.org", e);
        }
    }

    @Override
    public Set<PnfsId> index(IndexOption... options) throws CacheException
    {
        try {
            List<IndexOption> indexOptions = asList(options);

            if (indexOptions.contains(IndexOption.META_ONLY)) {
                return _views.collectKeys(Collectors.mapping(PnfsId::new, Collectors.toSet()));
            }

            Stopwatch watch = Stopwatch.createStarted();
            Set<PnfsId> files = _fileStore.index();
            _log.info("Indexed {} entries in {} in {}.", files.size(), _fileStore, watch);

            watch.reset().start();
            Set<String> records = _views.collectKeys(Collectors.toSet());
            _log.info("Indexed {} entries in {} in {}.", records.size(), _dir, watch);

            if (indexOptions.contains(IndexOption.ALLOW_REPAIR)) {
                for (String id : records) {
                    if (!files.contains(new PnfsId(id))) {
                        _log.warn(String.format(REMOVING_REDUNDANT_META_DATA, id));
                        _views.getStorageInfoMap().remove(id);
                        _views.getStateMap().remove(id);
                    }
                }
            }

            return files;
        } catch (EnvironmentFailureException e) {
            if (!isValid()) {
                throw new DiskErrorCacheException("Meta data lookup failed and a pool restart is required: " + e.getMessage(), e);
            }
            throw new CacheException("Meta data lookup failed: " + e.getMessage(), e);
        } catch (OperationFailureException e) {
            throw new CacheException("Meta data lookup failed: " + e.getMessage(), e);
        } catch (IOException e) {
            throw new DiskErrorCacheException("Meta data lookup failed and a pool restart is required: " + e.getMessage(), e);
        }
    }

    @Override
    public MetaDataRecord get(PnfsId id) throws CacheException
    {
        try {
            Path path = _fileStore.get(id);
            BasicFileAttributes attributes =
                    Files.getFileAttributeView(path, BasicFileAttributeView.class).readAttributes();
            if (!attributes.isRegularFile()) {
                throw new DiskErrorCacheException("Not a regular file: " + path);
            }
            return CacheRepositoryEntryImpl.load(this, id, attributes);
        } catch (EnvironmentFailureException e) {
            if (!isValid()) {
                throw new DiskErrorCacheException("Meta data lookup failed and a pool restart is required: " + e.getMessage(), e);
            }
            throw new CacheException("Meta data lookup failed: " + e.getMessage(), e);
        } catch (OperationFailureException e) {
            throw new CacheException("Meta data lookup failed: " + e.getMessage(), e);
        } catch (NoSuchFileException | FileNotFoundException e) {
            return null;
        } catch (IOException e) {
            throw new CacheException("Failed to read " + id + ": " + e.getMessage(), e);
        }
    }

    /**
     * TODO: The entry is not persistent yet!
     */
    @Override
    public MetaDataRecord create(PnfsId id, Set<Repository.OpenFlags> flags)
            throws CacheException
    {
        try {
            Path dataFile = _fileStore.get(id);
            if (Files.exists(dataFile)) {
                throw new DuplicateEntryException(id);
            }
            _views.getStorageInfoMap().remove(id.toString());
            _views.getStateMap().remove(id.toString());
            if (flags.contains(Repository.OpenFlags.CREATEFILE)) {
                Files.createFile(dataFile);
            }
            return new CacheRepositoryEntryImpl(this, id);
        } catch (IOException e) {
            throw new DiskErrorCacheException(
                    "Failed to create new entry " + id + ": " + e.getMessage(), e);
        }
    }

    @Override
    public void remove(PnfsId id) throws CacheException
    {
        Path f = _fileStore.get(id);
        try {
            Files.deleteIfExists(f);
        } catch (IOException e) {
            throw new DiskErrorCacheException("Failed to delete " + id);
        }
        try {
            _views.getStorageInfoMap().remove(id.toString());
            _views.getStateMap().remove(id.toString());
        } catch (EnvironmentFailureException e) {
            if (!isValid()) {
                throw new DiskErrorCacheException("Meta data update failed and a pool restart is required: " + e.getMessage(), e);
            }
            throw new CacheException("Meta data update failed: " + e.getMessage(), e);
        } catch (OperationFailureException e) {
            throw new CacheException("Meta data update failed: " + e.getMessage(), e);
        }
    }

    @Override
    public synchronized boolean isOk()
    {
        if (!_fileStore.isOk()) {
            return false;
        }

        Path tmp = _dir.resolve(".repository_is_ok");
        try {
            Files.deleteIfExists(tmp);
            Files.createFile(tmp);

            if (_database.isFailed()) {
                return false;
            }

            return true;
        } catch (IOException e) {
            _log.error("Failed to touch " + tmp + ": " + e.getMessage());
            return false;
        }
    }

    /**
     * Requests a data file from the CacheRepository. Used by the
     * entries to obtain a data file.
     */
    Path getPath(PnfsId id)
    {
        return _fileStore.get(id);
    }

    /**
     * Returns a database backed map of all StorageInfo objects.
     */
    StoredMap<String,StorageInfo> getStorageInfoMap()
    {
        return _views.getStorageInfoMap();
    }

    /**
     * Returns a database backed map of all state objects.
     */
    StoredMap<String,CacheRepositoryEntryState> getStateMap()
    {
        return _views.getStateMap();
    }

    /** Closes the database. */
    @Override
    public void close()
    {
        try {
            _database.close();
        } catch (DatabaseException e) {
            _log.error("Ignored: Could not close database: " + e.getMessage());
        }
    }

    /**
     * Returns the path
     */
    @Override
    public String toString()
    {
        return String.format("[data=%s;meta=%s]", _fileStore, _dir);
    }

    /**
     * Provides the amount of free space on the file system containing
     * the data files.
     */
    @Override
    public long getFreeSpace()
    {
        try {
            return _fileStore.getFreeSpace();
        } catch (IOException e) {
            _log.warn("Failed to query free space: " + e.toString());
            return 0;
        }
    }

    /**
     * Provides the total amount of space on the file system
     * containing the data files.
     */
    @Override
    public long getTotalSpace()
    {
        try {
            return _fileStore.getTotalSpace();
        } catch (IOException e) {
            _log.warn("Failed to query total space: " + e.toString());
            return 0;
        }
    }

    public boolean isValid()
    {
        return _database.getEnvironment().isValid();
    }

    public EnvironmentConfig getConfig()
    {
        return _database.getEnvironment().getConfig();
    }

    public Transaction beginTransaction()
    {
        return _database.getEnvironment().beginTransaction(null, null);
    }
}
