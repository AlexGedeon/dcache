Dcache SRM installation instructions

Requirements on the srm and pool nodes
   1. The nodes on which srm server (srm cell) and pool 
      nodes need to have the grid host certificate installed 
      on them. please refer to the doegrids.org for 
      instructions on how to obtain the grid host certificate 
      issued by doegrids certificate authority.
   2. There should be a postgres database server running on a 
      machine accessible by srm server, and there should be a 
      posgres user account created, capable of creating new 
      tables available.

CLASSPATH
     Since srm service is using two different toolkits for impementation of
      its soap server and soap client, and it is using the java cog kit from 
      Globus, the jar files neded for all of these products need to be copied
      to the server running srm, and they need to be included in the classpath,
      specified by dCacheSetup
     So the dCacheSetup will need to have a line specifying classpath that looks like this:
classpath=${thisDir}/../classes/srm.jar;${thisDir}/../classes/dcache-srm.jar:${thisDir}/../classes/glue/GLUE-STD.jar:${thisDir}/../classes/glue/dom.jar:${thisDir}/../classes/glue/servlet.jar:${thisDir}/../classes/glue/jnet.jar:${thisDir}/../classes/glue/jsse.jar:${thisDir}/../classes/glue/jsert.jar:${thisDir}/../classes/pgjdbc2.jar:${thisDir}/../classes/javatunnel.jar:${thisDir}/../classes/globus/junit.jar:${thisDir}/../classes/globus/cog-jglobus.jar:${thisDir}/../classes/globus/cog-url.jar:${thisDir}/../classes/globus/cryptix32.jar:${thisDir}/../classes/globus/cryptix-asn1.jar:${thisDir}/../classes/globus/cryptix.jar:${thisDir}/../classes/globus/jce-jdk13-125.jar:${thisDir}/../classes/globus/jgss.jar:${thisDir}/../classes/globus/junit.jar:${thisDir}/../classes/globus/log4j-1.2.8.jar:${thisDir}/../classes/globus/puretls.jar:${thisDir}/../classes/concurrent.jar:${thisDir}/../classes/axis:${thisDir}/../classes/axis/jaxrpc.jar:${thisDir}/../classes/axis/axis.jar:${thisDir}/../classes/axis/commons-discovery.jar:${thisDir}/../classes/axis/saaj.jar:${thisDir}/../classes/axis/commons-logging.jar:${thisDir}/../classes/axis/wsdl4j.jar:${thisDir}/../classes/globus/cog-axis.jar 

Non-standard DCache Services that srm relies upon
   1  Pin Manager.
      Pin Manager is used by srm for the performace of the so 
      called file "pin in cache" operation. When file is in pinned 
      state, it will not be deleted from cache to make room for 
      other incomming files. Pin Manager cell can be started by 
      adding the following lines to one of the dcache domain 
      configuration "batch" files:
    
    #
    #pin manager
    #
    create diskCacheV111.services.PinManager PinManager \
    " default -export  \
     -jdbcUrl=jdbc:postgresql://localhost/dcache \
     -jdbcDriver=org.postgresql.Driver \
     -dbUser=enstore \
     -dbPass=enstore"

     The configurable parameters are the folowing:
    -jdbcUrl url pointing the type and the location of the 
	database, which will be used by pin manager. For example 
	if the database is running on a host "hosta" on a nonstandard 
        port "12345", and the database name is "name1", this option 
        value would be "jdbc:postgresql://hosta:12345/name1".
     -jdbcDriver specifies the class name for the driver. Should 
        remain the same for the postgres database.
     -dbUser a name of the database user
     -dbPass a password for the database user, could be arbitrary 
	string if the host on which pin manager is running is 
	included in the posgres list of the trusted hosts.
     The two optional parameters are the 
     -poolManager and -pnfsManager, which allow the specification 
     of alternative names for the PoolManager and PnfsManager cells.
    2. GsiftpTransferManager
       This service is used by srm for performance of the transfers 
       from remote server to the dcache via gsiftp protocol.
       The GsiftpTransferManager cell is started by the folowing 
       "batch" command:

      #
      # RemoteGsiftpTransferManager
      #
      create diskCacheV111.services.GsiftpTransferManager
      RemoteGsiftpTransferManager
      \
        "default -export \
        -pool_manager_timeout=60 \
        -pnfs_manager_timeout=60 \
        -pool_timeout=300 \
        -mover_timeout=86400 \
        -max_transfers=3 \
      "
      The configurable parameters are the folowing:
      -pool_manager_timeout timeout in seconds for the PoolManager 
      message exchanges.
      -pnfs_manager_timeout timeout in seconds for the PnfsManager 
      message exchanges.
      -pool_timeout timeout in seconds before the first pool 
       message, confirming the creation of the mover arrives
      -mover_timeout the time in seconds before the transfer manager will 
       stop waiting for the completion of the started transfer and
       will try to kill the mover, and report the error to the caller
       (srm).
      -max_transfers maximum number of simultaneous transfers, if more
       transfers are scheduler, the transfer manager will fail them.
      
      3. Copy Manager, 
	This service is used by srm when the source and the destination
        files in srm  copy request are both local to the storage.
        Its configuration parameters are mostly the same as of
        GsiftpTransferManager. The example startup command follows:
        
	create diskCacheV111.doors.CopyManager CopyManager \
	"default -export \
	-pool_manager_timeout=60 \
	-pool_timeout=300 \
	-mover_timeout=86400 \
	-max_transfers=30 \
        "

SRM

	In order to start the srm server, the instance of the cell
	diskCacheV111.srm.dcache.Storage needs to be created. Here is 
 	the example of dcache batch file command starting srm cell, 
	illustrating most of the configurable parameters:

	create diskCacheV111.srm.dcache.Storage  srm_1 \
            "default -srmport=${srmPort1} \
            -export \
            -kpwd-file=${config}/dcache.kpwd \
            -srmmap=${config}/SRMServerV1.map \
            -pnfs-srm-path=/ \
            -buffer_size=1048576 \
            -tcp_buffer_size=1048576 \
            -parallel_streams=10 \
            -debug=true \
            -get-lifetime=86400000 \
            -put-lifetime=86400000 \
            -copy-lifetime=86400000 \
            -get-req-thread-queue-size=1000 \
            -get-req-thread-pool-size=30 \
            -get-req-max-waiting-requests=1000 \
            -get-req-ready-queue-size=1000 \
            -get-req-max-ready-requests=30 \
            -get-req-max-number-of-retries=10 \
            -get-req-retry-timeout=60000 \
            -get-req-max-num-of-running-by-same-owner=10 \
            -put-req-thread-queue-size=1000 \
            -put-req-thread-pool-size=30 \
            -put-req-max-waiting-requests=1000 \
            -put-req-ready-queue-size=1000 \
            -put-req-max-ready-requests=30 \
            -put-req-max-number-of-retries=10\
            -put-req-retry-timeout=60000 \
            -put-req-max-num-of-running-by-same-owner=10 \
            -copy-req-thread-queue-size=1000 \
            -copy-req-thread-pool-size=8 \
            -copy-req-max-waiting-requests=1000 \
            -copy-req-max-number-of-retries=30\
            -copy-req-retry-timeout=6000 \
            -copy-req-max-num-of-running-by-same-owner=10 \
            -recursive-dirs-creation=true \
            -jdbcUrl=jdbc:postgresql://localhost/dcache \
            -jdbcDriver=org.postgresql.Driver \
            -dbUser=enstore \
            -dbPass=enstore \
            -advisory-delete=false \
            "    
       
	The available configuration options are:
        -kpwd-file specifies the location of dcache authorization 
	"database" file.

        -srmmap specifies the location of the map file, used by the srm
	server, for mapping java structures to the correct soal xml structures
        according to the srm wsdl document. This is a required argument.
	srm repository contains this file at srm/lib/SRMServerV1.map path.

        -pnfs-srm-path specifies the root of the srm within the pnfs
	namespace. Essentially this means that the value of this option 
	will be prepended to all the local storage paths given to srm 
        server.
        -buffer_size and -tcp_buffer_size specify the size of memory, in
	bytes, and socket buffer size, in bytes, to use with the embeded 
	gsiftp clients, when performing transfers between the storage and 
	a gsiftp server.
        -parallel_streams specifies the max number of parallel streams to be
	used by the embeded gsiftp client.
        -debug tells if extra debug info should be logged. Most of the debug 
        logging can be turned off by setting the printout domain variable to
	error. Usually this is done in  the first line of the dcache batch
	file.
        -recursive-dirs-creation turnes on and off the the automatic creation
	of the unexsistent directories, in case of put/copy requests.
        -jdbcUrl, -jdbcDriver, -dbUser, -dbPass: these options have exactly
	same meaning as the same options of the PinManager.
        -get-lifetime, -put-lifetime, -copy-lifetime specify the lifetimes, in 
        milliseconds, of the srm get, put and copy requests respectively.

        The meanings of the rest of the options from the example might be
 	explained only after the working of the srm scheduler is described.
        Please note that the following explanation is a simplification.
        SRM Scheduler executes the instances of the SRM Job classes.For
	scheduler, execution of the job is the execution of the job's run
	method in one of the threads. Jobs are	initially in the Pending state. 
	Once the scheuler receives the job, it  puts it in the TQueued state and 
	puts it on the Thread Queue.
	Scheduler utilizes the pool of the java threads that will be actually execute 
	the jobs "run" methods. Once a thread in the pool becomes available,
	the first job from the Thread Queue is removed, and this job's state is
	changed to running. The pool thread starts the execution of job's run method.
        Once the run method returns, the state of the job can still remain
	"Running", or it might have changed to  "Done" or "AsyncWait". 

        If the state is still "Running", it will be placed on the ready queue,
	the job execution is completed and it now waits to be put to "Ready"
	state by the scheduler;
	if it is "AsyncWait" this means that job is partially completed, and
	it now waits for the internal event to continue execution; if it "Done", 
	the job needs no further processing.
        
        To limit the number of simultaneous transfer by the srm clients, in
	cases when srm server does not perform the transfer itself, (cases of
	"get" and "put" requests) the number of the jobs that are "Ready" is
	limited to a certain number. The rest of the requests, which are ready 
        to be "Ready" are put on the "Ready" queue. Once the clients finish
	the transfers, they notify the system by changing the state of the put
        or get file requests to "Done". If users never do that the request
	changes its state automatically upon the expiration of the request
	lifetime. Once more "Ready" spots become available the number requests
	are removed from the Ready queue and their state changes to "ready".
        
        -advisory-delete=<true or false>, if it is set to true, advisory
        delete srm function  will delete pnfs entry and mark all replicas as
	cached, it is set to false, then advisory delete will return success
        to the caller without any modification on the storage side.
        
        In the dcache srm there are three instances of the scheduler, one for
	each possible type of srm requests: copy, get and put.
        in the description of the following options type is 
         
        -[type]-req-thread-queue-size - maximum number of the requests in the
	thread queue

        -[type]-req-thread-pool-size - maximum number of threads in the thread 
	pool. This parameter is especially important for the copy requests,
	since copy of each file is performed in a separate thread. This number
	for copy request should be less then the -max_transfers parameter of
	the transfer managers.

        -[type]-req-max-waiting-requests - maximum number of the requests in
        the async wait jobs
         
        -[type]-req-ready-queue-size - maximum number of the requests on the 
	ready queue, the copy jobs never get to the ready state, to this and
	following parameters  are not important for copy scheduler.

        -[type]-req-max-ready-requests
	this parameter is important for the the put and get
	requests, and it is equivalent to the number of the transfer urls
	given  out to the clients, who are actively transfering (or intend to 
        transfer).

        -[type]-req-max-number-of-retries
        a number of timesa the job is allowed to fail and to be retried,
	before srm should give up on it, and return the error to the user.

        -[type]-req-max-num-of-running-by-same-owner
        The job owner is roughly equivalent to the user account name in kpwd
	file.
        When the jobs are removed from the Thread and Ready Queue, their
	owner" is taken in consideration. If there more then this number of
	the requests running for a certain owner, then their jobs will not be
	removed from the queue, even if they are first in the queue, if there
	are  jobs belonging to some other owner, for whom this nymber was not 
	reached yet. This will not lead to the underutilization of the
	system, if there is only one owner's jobs running, since they all will
	get scheduled to occupy all available scheduler threads or ready
	spots.

	Other available options are (these are not recommended to be used so
	they are not explained here) :
        -poolManager, 
	-pnfsManager, 
        -proxies-directory
        -url-copy-command
        -timeout-command
        -usekftp
        -globus-url-copy
        -use-urlcopy-script
        -use-dcap-for-srm-copy
        -use-gsiftp-for-srm-copy
        -use-http-for-srm-copy
        -use-ftp-for-srm-copy
        -save-memory

        for more info please refer to dcache web site www.dcache.org, fnal srm
	web site, www-isd.fnal.gov/srm.
