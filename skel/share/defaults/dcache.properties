#  -----------------------------------------------------------------------
#     dCache default values
#  -----------------------------------------------------------------------
#
#   This Java properties file contains default values for dCache
#   configuration parameters. All values can be redefined in
#   etc/dcache.conf. Do not modify any values here as your changes
#   will be lost when you next upgrade.
#
#   Many parameters appear under two different names: A legacy name
#   from the old dCacheSetup file used before dCache 1.9.7, and a new
#   name following a hierarchical naming scheme with dots. The legacy
#   names are deprecated and will be removed at some point in the
#   future.

#  -----------------------------------------------------------------------
#     Parameters related to dCache startup
#  -----------------------------------------------------------------------

# If defined, the UID of the java process will be set.  Notice that
# log files will continue to be generated with the user id that
# invoked the init script. When undefined or left blank, the UID will
# not be changed.
dcache.user=

# Type of namespace backend. Legal values are pnfs and chimera.
dcache.namespace=chimera

# The layout determines which domains to start.
dcache.layout=single

# Base directory for layout files
dcache.layout.dir=${dcache.paths.etc}/layouts

# The layout file describes the domains of a layout
dcache.layout.uri=file:${dcache.layout.dir}/${dcache.layout}.conf

# Directory for PID files
dcache.pid.dir=/var/run

# PID file for daemon wrapper script
dcache.pid.java=${dcache.pid.dir}/dcache.${domain.name}-java.pid

# PID file for Java process
dcache.pid.daemon=${dcache.pid.dir}/dcache.${domain.name}-daemon.pid

# Directory for log files
dcache.log.dir=/var/log

# Path to log file
dcache.log.file=${dcache.log.dir}/${domain.name}.log

# This variable describes what should be done with an existing log
# file when a domain is started.  The options are either to rename
# LOGFILE to LOGFILE.old so allowing a new log file to be created, or
# to retain the log file and subsequent logging information will be
# appended.
#
# The valid values are:
#      new
#      keep
dcache.log.mode=keep

# Logback configuration file
dcache.log.configuration=file:${dcache.paths.etc}/logback.xml

# Delay, in seconds, between automatic restarts of a crashed domain
dcache.restart.delay=10

# Directory used for creating the files to surpress automatic restart
dcache.restart.dir=/tmp

# File used to suppress automatic restart
dcache.restart.file=${dcache.restart.dir}/.dcache-stop.${domain.name}

# Java maximum heap size
dcache.java.memory.heap=512m

# Java maximum direct buffer size
dcache.java.memory.direct=512m

# Path where to store heapdumps
dcache.java.oom.location=${dcache.log.dir}

# Extra jars to add to the class path
dcache.java.classpath=

#  ---- The Library path
#
#   This is currently not used. It might contain .so libraries for JNI.
#
dcache.java.library.path=${dcache.paths.lib}

# Hook to add additional Java VM options without redefining
# dcache.java.options.
dcache.java.options.extra=

# Java VM options
dcache.java.options=\
    -server \
    -Xmx${dcache.java.memory.heap} \
    -XX:MaxDirectMemorySize=${dcache.java.memory.direct} \
    -Dsun.net.inetaddr.ttl=${net.inetaddr.lifetime} \
    -Dorg.globus.tcp.port.range=${net.wan.port.min},${net.wan.port.max} \
    -Djava.net.preferIPv4Stack=true \
    -Dorg.dcache.dcap.port=${pool.dcap.port} \
    -Dorg.dcache.net.tcp.portrange=${net.lan.port.min}:${net.lan.port.max} \
    -Dorg.globus.jglobus.delegation.cache.lifetime=${gsi.delegation.cache.lifetime} \
    -Dorg.globus.jglobus.crl.cache.lifetime=${gsi.crl.cache.lifetime} \
    -Djava.security.krb5.realm=${kerberos.realm} \
    -Djava.security.krb5.kdc=${kerberos.key-distribution-center-list} \
    -Djavax.security.auth.useSubjectCredsOnly=false \
    -Djava.security.auth.login.config=${kerberos.jaas.config} \
    -Dliquibase.should.run=${db.schema.auto} \
    -XX:+HeapDumpOnOutOfMemoryError \
    -XX:HeapDumpPath=${dcache.java.oom.location}/${domain.name}-oom.hprof \
    -javaagent:${dcache.paths.classes}/lib/spring-instrument-3.0.5.RELEASE.jar \
    ${dcache.java.options.extra}

# The following property describes whether dCache should run under Terracotta.
# It is only supported by the srm service at this time,so do not enable it in
# dcache.conf; instead, enable it, in the layout file, for the domain the srm
# service runs within.
#
#  For example:
#
#    [srmDomain]
#     dcache.terracotta.enabled=true
#     dcache.terracotta.install.dir=/opt/terracotta
#
#    [srmDomain/srm]
#    [srmDomain/spacemanager]

dcache.terracotta.enabled=false

# The following parameter specifies the location of Terracotta
# If dcache.terracotta.enabled is true then this must be specified as well
dcache.terracotta.install.dir=

# Location of the Terracotta configuration file
dcache.terracotta.config.path=${dcache.paths.etc}/tc-config.xml

#  -----------------------------------------------------------------------
#     Parameters related to what runs inside a domain
#  -----------------------------------------------------------------------

# A batch file to execute in every domain before services are loaded.
domain.preload=file:${dcache.paths.share}/cells/preload.fragment

# Directory containing service batch files (the batch files that start
# dCache cells)
domain.service.dir=${dcache.paths.share}/services

# URI to service batch file
domain.service.uri=file:${domain.service.dir}/${domain.service}.batch


#  -----------------------------------------------------------------------
#     Generic network related parameters
#  -----------------------------------------------------------------------

# Port range used for transfers using typical WAN protocols
net.wan.port.min=20000
net.wan.port.max=25000

# Port range used for transfers using typical LAN protocols
net.lan.port.min=33115
net.lan.port.max=33145

# Java DNS cache (seconds)
net.inetaddr.lifetime=1800

#  -----------------------------------------------------------------------
#     Protocol specific options
#  -----------------------------------------------------------------------

# GSI caching parameters (ms)
gsi.delegation.cache.lifetime=30000
gsi.crl.cache.lifetime=60000


#  ---- Kerberos Configuration
#
#  Your kerberos 5 realm, used by Kerberos dcap and FTP doors
#
#  (kerberosRealm is a legacy property, use kerberos.realm to
#  configure)
kerberosRealm=EXAMPLE.ORG
kerberos.realm=${kerberosRealm}

#  A comma-separated list of KDC hostnames.  localhost may be used if
#  a KDC multiplexer is running on the same machine as the Kerberos FTP doors.
#
#  (kerberosKdcList is a legacy property, use
#  kerberos.key-distribution-center-list to configure)
kerberosKdcList=localhost
kerberos.key-distribution-center-list=${kerberosKdcList}

#  Service Principle Names for the Kerberos doors.  You shouldn't need
#  to alter these.
#
#  (kerberosScvPrincipal is a legacy property, use
#  kerberos.service-principle-name to configure)
kerberosScvPrincipal=ftp/${host.fqdn}@${kerberos.realm}
kerberosftp/kerberos.service-principle-name=${kerberosScvPrincipal}
kerberosdcap/kerberos.service-principle-name=host/${host.fqdn}@${kerberos.realm}


#  Template JAAS configuration files are available in the
#  ${dcache.paths.etc} directory as jgss.conf.template and
#  jgss_host.conf.template.  Please create a copy of these files
#  without the .template ending and modify their content as
#  appropriate.  The minimum configuration is to change the principle
#  value, replacing "door.example.org" with the FQDN of the door and
#  replacing "EXAMPLE.ORG" with the Kerberos Realm.
#
#  The file jgss.conf is suitable for a domain running a Kerberos FTP
#  door and jgss_host.conf is suitable for a domain running a Kerberos
#  dcap door.  Only one file may be specified per domain.
#
#  (authLoginConfig is a legacy property, use kerberos.jaas.config to
#  configure)
authLoginConfig=${dcache.paths.etc}/jgss.conf
kerberos.jaas.config=${authLoginConfig}
#kerberos.jaas.config=${dcache.paths.etc}/jgss.conf
#kerberos.jaas.config=${dcache.paths.etc}/jgss_host.conf


#  -----------------------------------------------------------------------
#          Cell Communication
#  -----------------------------------------------------------------------

#  ---- Which message broker implementation to use
#
#   Valid values are: cells, embedded-jms, jms, none
#   The default is: cells
#
#   Selects between various message brokers. The message broker
#   determines how dCache domains communicate with each other.
#
#   'cells' is the classic cells based system. It relies on a central
#   location service that all domains connect to. The host, port and
#   domain of this service is defined by broker.host, broker.port and
#   broker.domain.
#
#   'jms' connects to a JMS broker. By default dCache uses Apache
#   Active MQ as its JMS implementation.
#
#   'hybrid' is a hybrid broker. An embedded JMS broker is started in
#   the domain specified by broker.domain. At the same time a classic
#   cells location service is instantiated in the same domain. Thus
#   both 'cells' and 'jms' can be used by other domains to connect to
#   the broker.
#
#   'none' no broker connection is establish. This is used for single
#   domain deployments.
#
messageBroker=cells
broker.scheme=${messageBroker}

#  ---- Broker for interdomain communication
#
#   By default both the cells and the hybrid broker styles use a star
#   topology with all messages going through a central domain. This
#   domain is usually dCacheDomain, but any domain can be used.
#
#   As all other domains need to connect to the broker, broker.host
#   has to be configured throughout the dCache instance unless the
#   broker runs on the local host or if there is no broker.
#
broker.domain=dCacheDomain
broker.host=${serviceLocatorHost}
broker.port=${serviceLocatorPort}
serviceLocatorHost=localhost
serviceLocatorPort=11111

#  ---- Port and host used for ActiveMQ broker
#
#   Determines the host and port used for the ActiveMQ broker. The
#   host defaults to ${broker.host}. Only used if messageBroker is set
#   to either jms or hybrid.
#
amqHost=${broker.host}
amqPort=11112
amqSSLPort=11113
broker.amq.host=${amqHost}
broker.amq.port=${amqPort}
broker.amq.ssl.port=${amqSSLPort}

#  ---- Connection URL for ActiveMQ
#
#   By default, the ActiveMQ connection URL is formed from amqPort and
#   amqHost. amqUrl may be used to configure more advanced broker
#   topologies. Consult the ActiveMQ documentation for possible values.
#   The default is 'failover:tcp://${amqHost}:${amqPort}'
#
amqUrl=failover:tcp://${amqHost}:${amqPort}
broker.amq.url=${amqUrl}

#  ---- ActiveMQ spool directory
#
#   Determines the spool directory used by the embedded ActiveMQ
#   broker. Only used when messageBroker is set to embedded-jms and
#   only used by dCacheDomain.
#
amqSpool=/var/spool/d-cache/amq
broker.amq.spool=${amqSpool}

#  -----------------------------------------------------------------------
#          Cell naming
#  -----------------------------------------------------------------------

authdcap/cell.name=DCap-${host.name}
dcap/cell.name=DCap-${host.name}
gridftp/cell.name=GFTP-${host.name}
gsidcap/cell.name=DCap-gsi-${host.name}
httpd/cell.name=httpd
httpdoor/cell.name=HTTP-${host.name}
info/cell.name=info
nfsv41/cell.name=NFSv41-${host.name}
srm/cell.name=SRM-${host.name}
statistics/cell.name=PoolStatistics
ftp/cell.name=FTP-${host.name}
kerberosftp/cell.name=KFTP-${host.name}
kerberosdcap/cell.name=DCap-Kerberos-${host.name}
poolmanager/cell.name=PoolManager
gplazma/cell.name=gPlazma
loginbroker/cell.name=LoginBroker
spacemanager/cell.name=SrmSpaceManager

#  -----------------------------------------------------------------------
#          Cell addresses of major dCache components
#  -----------------------------------------------------------------------

pnfsmanager=PnfsManager
poolmanager=PoolManager
gplazma=gPlazma
loginBroker=LoginBroker
spacemanager=SrmSpaceManager

#  -----------------------------------------------------------------------
#          Login broker
#  -----------------------------------------------------------------------
#
#   A login broker maintains a list of doors in dCache. Each door is
#   configured to register with zero or more login brokers. By default
#   all doors other than the SRM door register with a single central
#   login broker.
#

#  ---- How often a door register with its login brokers
#
#   The time in seconds between two registrations.
#
loginBrokerUpdateTime=5

#  ---- Threshold for load changes in a door to trigger reregistration
#
#   The registration with a login broker contains information about
#   the current load of a door. If the load changes rapidly, then a
#   door may updates its registration before the next scheduled update
#   time. This parameter specifies the fraction of the load that
#   triggers a reregistration.
loginBrokerUpdateThreshold=0.1

#  -----------------------------------------------------------------------
#          Components
#  -----------------------------------------------------------------------

#   To activate Replica Manager you need make changes in 3 places:
#    1) you need to execute the replica service somewhere in your
#       dCache installation by enabling it in a layout file
#    2) configure the service in etc/dcache.conf file on node where
#       the replica service is running
#    3) define Resilient pool group(s) in PoolManager.conf on the host
#       running the poolmanager service

#  ---- Will Replica Manager be started?
#
#   Values:  no, yes
#   Default: no
#
#   This has to be set to 'yes' on every node, if there is a replica
#   manager in this dCache instance. Where the replica manager is
#   started is controlled in 'etc/node_config'. If it is not started
#   and this is set to 'yes' there will be error messages in
#   log/dCacheDomain.log. If this is set to 'no' and a replica
#   manager is started somewhere, it will not work properly.
#
#replicaManager=no

#  ---- Which pool-group will be the group of resilient pools?
#
#   Values:  <pool-Group-Name>, a pool-group name existing in the PoolManager.conf
#   Default: ResilientPools
#
#   Only pools defined in pool group ResilientPools in
#   config/PoolManager.conf will be managed by ReplicaManager. You
#   must edit config/PoolManager.conf to make the replica manager
#   work. To use another pool group defined in PoolManager.conf for
#   replication, please specify group name by changing the setting:
#       #resilientGroupName=ResilientPools
#   Please scroll down "replica manager tuning" make this and other
#   changes.


#  ---- SSL Server certificate
#
#   This parameter specifies the path to the file containing the
#   PKCS12 encoded server certificate used for SSL. The host certificate
#   in /etc/grid-security/ needs to be converted to PKCS12 format before
#   it can be used with SSL. Use the 'bin/dcache import
#   hostcert' command to perform this task. This is used in Webadmin and WebDAV
#
#   Notice that for GSI the host cetificate in /etc/grid-security/ is used
#   directly.
#
keyStore=${dcache.paths.etc}/hostcert.p12

#  ---- Password for SSL server certificate
#
#   This parameter specifies the password with which the PKCS12 encoded
#   server certificate is encrypted.
#
keyStorePassword=dcache

#  ---- Trusted SSL CA certificates
#
#   This parameter specifies the path to a Java Keystore containing
#   the the trusted CA certicates used for SSL. The CA certificates
#   in /etc/grid-security/certificates/ need to be converted into a
#   Java Keystore file before they can be used with SSL. Use the
#   'bin/dcache import cacerts' command to perform this task.
#   This is used in Webadmin and WebDAV.
#
#   Notice that for GSI the CA cetificates in
#   /etc/grid-security/certificates/ are used directly.
#
trustStore=${dcache.paths.etc}/certificates.jks

#  ---- Password for trusted SSL CA certificates
#
#   This parameter specifies the password with which the Java Keystore
#   containing the trusted CA certificates is encrypted.
#
trustStorePassword=dcache


#  -----------------------------------------------------------------------
#          Filesystem Locations
#  -----------------------------------------------------------------------

# Legacy variable
(deprecated)ourHomeDir=${dcache.home}

#  ---- Location of the configuration files
#
#   Do not change unless you know what you are doing.
#
config=${dcache.paths.config}

#  ---- Location of the ssh
#
#   Do not change unless you know what you are doing.
#
keyBase=${dcache.paths.config}

#  ---- SRM/GridFTP authentication file
#
#   Do not change unless you know what you are doing.
#
kpwdFile=${dcache.paths.etc}/dcache.kpwd

#  ---- Admin door history file
#
#   The admin door can store a command history in a file. This makes
#   the history persistent over multiple logins. To enable this
#   feature, set adminHistoryFile to the path of the file that should
#   be used to store the history. The recommended path is
#   /var/opt/d-cache/adminshell_history. Notice that missing
#   directories are not created automatically.
#
#adminHistoryFile=



#  -----------------------------------------------------------------------
#         gPlazma tuning
#  -----------------------------------------------------------------------
#
#   Do not change unless you know what you are doing.
#
gplazmaPolicy=${dcache.paths.etc}/dcachesrm-gplazma.policy
gPlazmaNumberOfSimutaneousRequests=30
gPlazmaRequestTimeout=180
#
useGPlazmaAuthorizationModule=false
useGPlazmaAuthorizationCell=true
delegateToGPlazma=false



#  -----------------------------------------------------------------------
#         dcap tuning
#  -----------------------------------------------------------------------
#
#kerberosdcapIoQueue=
#kerberosdcapIoQueueOverwrite=denied
#kerberosdcapMaxLogin=1500
#gsidcapIoQueue=
#gsidcapIoQueueOverwrite=denied
#gsidcapMaxLogin=1500
#dcapIoQueue=
#dcapIoQueueOverwrite=denied
#dcapMaxLogin=1500


#  -----------------------------------------------------------------------
#         common to gsiftp and srm
#  -----------------------------------------------------------------------

#  ---- Whether the SRM Space Manager should be enabled.
#
srmSpaceManagerEnabled=no

#  ---- Whether implicit space reservations should be enabled.
#
#   The following variable will have no effect unless the SRM Space
#   Manager is enabled.
#
#srmImplicitSpaceManagerEnabled=yes

overwriteEnabled=false

# ---- Host certificate refresh period in seconds.
#
# This option nfluences in which intervals the host certificate will be
# reloaded on a running door. Currently supported by the SRM door.
hostCertificateRefreshPeriod=43200

# ---- Trust anchor refresh period in seconds.
#
# Grid-based authentication usually requires to load a set of certificates
# that are accepted as certificate authorities. This option influences in
# which interval these trust anchors are reloaded.
# Currently supported by the SRM door.
trustAnchorRefreshPeriod=43200



#  -----------------------------------------------------------------------
#          Web Interface Configuration
#  -----------------------------------------------------------------------

#  ---- Directory locations for dCache web interface
#
#   The following two variables specify the absolute location of the
#   image and style directories for the dCache-internal web server.
#
#   Do not change them unless you know what you are doing.
#
images=${dcache.paths.docs}/images
styles=${dcache.paths.docs}/styles



#  -----------------------------------------------------------------------
#          Network Configuration
#  -----------------------------------------------------------------------

#  ---- Port Numbers for the various services
#
#   Do not change these variables unless you know what you are doing.
#
dCapPort=22125
dCapGsiPort=22128
dCapKerberosPort=22725
ftpPort=22126
gsiFtpPortNumber=2811
kerberosFtpPort=22127
srmPort=8443
httpPortNumber=2880

dcap/port=${dCapPort}
authdcap/port=${dCapPort}
gsidcap/port=${dCapGsiPort}
kerberosdcap/port=${dCapKerberosPort}

ftp/port=${ftpPort}
gridftp/port=${gsiFtpPortNumber}
kerberosftp/port=${kerberosFtpPort}

srm/port=${srmPort}
http/port=${httpPortNumber}


#------ SRM Network Identities------------------------------------------------

#------------------srmHost----------------------------------------------------
# For certain operations srm needs to know its domain name.
# The variable "srmHost" can be used to override the default value.
# If this value is not set, the value is detected automatically and
# it is equivalent to the output of the unix hostname program
# ----------------------------------------------------------------------------
srmHost=${host.fqdn}

#------------------localSrmHosts----------------------------------------------
# A host part of the srm url (surl) is used to determine if the surl
# references file in this storage system.
# In case of the copy operation, srm needs to be able to tell the
# local surl from the remote one.
# Also SRM needs to  refuse to perform operations on non local srm urls
# localSrmHosts is a comma separated list of hosts that will be cosidered
# local by this srm server.
# This parameter might need to be defined as a list because in case of the
# multihomed or distributed server it may have more than one network name.
# If localSrmHosts is not specified, srmHost will be used
# ----------------------------------------------------------------------------
localSrmHosts=${srmHost}


#  ---- GridFTP port range
#
#   Do not change unless you know what you are doing.
#
clientDataPortRange=${net.wan.port.min}:${net.wan.port.max}

#  ---- Port Numbers for the monitoring and administration
#
#   Do not change unless you know what you are doing.
#
adminPort=22223
admin/port=${adminPort}


httpdPort=2288
sshPort=22124
#   Telnet is only started if the telnetPort line is uncommented.
#   This should be for debug use only.
#telnetPort=22123

httpd/port=${httpdPort}


#  -----------------------------------------------------------------------
#          Database Configuration
#  -----------------------------------------------------------------------
#
#   The srmDbHost variable is obsolete.  For compatibility reasons,
#   it is still used if set and the following variables are not.
#
#   The current setup assumes that one or more PostgreSQL servers are
#   used by the various dCache components.  Currently the database user
#   'srmdcache' with password 'srmdcache' is used by all components.
#   They use the databases 'dcache', 'replicas', 'companion' and
#   'billing'.  However, these might be located on separate hosts.
#
#   The most performant configuration is to have the database server
#   running on the same host as the dCache component that will
#   access it.  Therefore, the default value for all the following
#   variables is 'localhost'.  Uncomment and change these variables
#   only if you have a reason to deviate from this scheme.
#
#   For example, one valid deployment would be to put the 'billing'
#   database on different host than the pnfs server database and
#   companion, but keep the httpDomain on the admin host.

#  ---- Whether to manage database schemas automatically
#
#   When true, database schemas will be automatically updated when
#   needed. Not all services support this setting. This settings
#   applies to a complete domain and must not be defined at the
#   service level.
db.schema.auto=true

#  ---- pnfs Companion Database Host
#
#   Do not change unless you know what you are doing.
#
#   Database name: companion
#
#companionDatabaseHost=localhost

#  ---- pnfs Manager interface to Deletion Resigistration Configuration
#
#   Deletion Registration functionality in pnfs, when enabled, creates a
#   record of each file deletion in pnfs namespace. Dcache does not delete
#   precious or online data files in pools if a deletion registration record
#   is not present. Usage of trash database is recommended in case of the
#   pnfs namespace, as pnfs can report files as not being found when some
#   components of pnfs are not running. This issue does not affect Chimera.
#
#   There are two ways to connect to the database containing
#   registration of deletions of files in pnfs  namespace, direct
#   database or through a special ".()()" file in pnfs nfs interface
#   To configure access though pnfs nfs set the value of
#   pnfsDeleteRegistration to pnfs:
#   To configure dirrect access to postgres, set pnfsDeleteRegistration
#   to jdbc url jdbc:postgresql://localhost/trash and set
#   pnfsDeleteRegistrationDbUser and pnfsDeleteRegistrationDbPass to
#   postgres user name to password values.
#   Set value to "" to disable usage the registration of deletion
#   Default value pnfsDeleteRegistration is "pnfs:"
#
#
#pnfsDeleteRegistration=jdbc:postgresql://localhost/trash
#pnfsDeleteRegistration=pnfs:
#pnfsDeleteRegistrationDbUser=srmdcache
#pnfsDeleteRegistrationDbPass=

#  ---- SRM Database Host
#
#   NB. If the srmDbHost variable is set and the following variable
#   is not then the value of srmDbHost is used.
#
#   Do not change unless you know what you are doing.
#
#   Database name: dcache
#
#srmDatabaseHost=localhost

#  ---- Space Manager Database Host
#
#   NB. If the srmDbHost variable is set and the following variable
#   is not then the value of srmDbHost is used.
#
#   Do not change unless you know what you are doing.
#
#   Database name: dcache
#
spaceManagerDatabaseHost=localhost

#  ---- Replica Manager database settings
#
#   Do not change unless you know what you are doing.
#
#   Database name: replicas
#
#replicaManagerDatabaseHost=localhost
#replicaDbName=replicas
#replicaDbUser=srmdcache
#replicaDbPassword=srmdcache
#replicaPasswordFile=
#resilientGroupName=ResilientPools
#replicaPoolWatchDogPeriod=600
#replicaWaitDBUpdateTimeout=600
#replicaExcludedFilesExpirationTimeout=43200
#replicaDelayDBStartTimeout=1200
#replicaAdjustStartTimeout=1200
#replicaWaitReplicateTimeout=43200
#replicaWaitReduceTimeout=43200
#replicaDebug=false
#replicaMaxWorkers=6
#replicaMin=2
#replicaMax=3


#  ---- Allow overwrite of existing files via GSIdCap
#
#   allow=true, disallow=false
#
truncate=false




#  ---- Obsolete properties
#
(obsolete)useFilesystem=



#  -----------------------------------------------------------------------
#         Directory Pools
#  -----------------------------------------------------------------------
#
#directoryPoolPnfsBase=/pnfs/fs




#  -----------------------------------------------------------------------
#          Srm Settings for experts
#  -----------------------------------------------------------------------
#

#remoteGsiftpIoQueue=

#srmVersion=version1
#pnfsSrmPath=/
#parallelStreams=10

#srmAuthzCacheLifetime=60

#srmGetLifeTime=14400000
#srmBringOnlineLifeTime=14400000
#srmPutLifeTime=14400000
#srmCopyLifeTime=14400000


#srmTimeout=3600
#srmVacuum=true
#srmVacuumPeriod=21600
#srmProxiesDirectory=/tmp
#srmBufferSize=1048576
#srmTcpBufferSize=1048576
#srmDebug=true

#srmGetReqThreadQueueSize=10000
#srmGetReqThreadPoolSize=250
#srmGetReqMaxWaitingRequests=1000
#srmGetReqReadyQueueSize=10000
#srmGetReqMaxReadyRequests=2000
#srmGetReqMaxNumberOfRetries=10
#srmGetReqRetryTimeout=60000
#srmGetReqMaxNumOfRunningBySameOwner=100

# Time in milliseconds after which get requests are handled
# asynchronously. Set to 'infinity' to disable asynchronous
# processing.
#
#srmGetReqSwitchToAsynchronousModeDelay=0

#srmBringOnlineReqThreadQueueSize=10000
#srmBringOnlineReqThreadPoolSize=250
#srmBringOnlineReqMaxWaitingRequests=1000
#srmBringOnlineReqReadyQueueSize=10000
#srmBringOnlineReqMaxReadyRequests=2000
#srmBringOnlineReqMaxNumberOfRetries=10
#srmBringOnlineReqRetryTimeout=60000
#srmBringOnlineReqMaxNumOfRunningBySameOwner=100

# Time in milliseconds after which bring online requests are handled
# asynchronously. Set to 'infinity' to disable asynchronous
# processing.
#
#srmBringOnlineReqSwitchToAsynchronousModeDelay=0

#srmPutReqThreadQueueSize=10000
#srmPutReqThreadPoolSize=250
#srmPutReqMaxWaitingRequests=1000
#srmPutReqReadyQueueSize=10000
#srmPutReqMaxReadyRequests=1000
#srmPutReqMaxNumberOfRetries=10
#srmPutReqRetryTimeout=60000
#srmPutReqMaxNumOfRunningBySameOwner=100

# Time in milliseconds after which put requests are handled
# asynchronously. Set to 'infinity' to disable asynchronous
# processing.
#
#srmPutReqSwitchToAsynchronousModeDelay=0

#srmCopyReqThreadQueueSize=10000
#srmCopyReqThreadPoolSize=250
#srmCopyReqMaxWaitingRequests=1000
#srmCopyReqMaxNumberOfRetries=10
#srmCopyReqRetryTimeout=60000
#srmCopyReqMaxNumOfRunningBySameOwner=100

#srmPoolManagerTimeout=300
#srmPoolTimeout=300
#srmPnfsTimeout=300
#srmMoverTimeout=7200
#remoteCopyMaxTransfers=150
#remoteHttpMaxTransfers=30
#remoteGsiftpMaxTransfers=${srmCopyReqThreadPoolSize}
#
srmDbHost=localhost
srmDbName=dcache
srmDbUser=srmdcache
srmDbPassword=srmdcache
srmDbLogEnabled=false

#  The transport used when contacting remote SRM
#  instances.  This is only used for third-party
#  copies (srmCopy).
srmClientTransport=GSI

# ---- Jetty GSI connector that should be used in the SRM door
#
# srmJettyConnectorType can be one of {sync, async}
# async means that a channel/selector based Jetty GSI connector is used, while
# sync means that a blocking (synchronous) GSI connector is used.
#
# Use the selector/channel based connector if you expect a very large number of
# simultaneous SRM connections.
#
srmJettyConnectorType=sync

#
# The security transport SRM is to use.  The possible values are SSL or GSI.  GSI
# (Grid Security Infrastructure) is the commonly deployed protocol, but SSL is
# the industrial standard.
#
srmGssMode=GSI


#
# srmls settings follow
#
# The following variable turnes of asynchronous srmls
# behavior. SrmLs is executed in non-blocking mode on a
# thread queue in the server and client is given request token.
# Client can query status  of request using this token. Async.
# srmls avoids holding connections to the server while srmls is
# executed.
#
(deprecated)srmAsynchronousLs=false
#
# Number of entries allowed to be returnes in a single srmls request
# (e.g. number of files in directory)
#
#srmLsMaxNumberOfEntries=1000
#
# Maximum recursion depth
#
#srmLsMaxNumberOfLevels=100
#
# Srmls schedule parameters:
#
#srmLsRequestThreadQueueSize=1000
#srmLsRequestThreadPoolSize=30
#srmLsRequestMaxWaitingRequests=1000
#srmLsRequestMaxNumberOfRetries=10
#srmLsRequestRetryTimeout=60000
#srmLsRequestMaxNumberOfRunningBySameOwner=100
#srmLsRequestLifetime=3600000

#   Time in milliseconds after which put requests are handled
#   asynchronously. Set to 'infinity' to disable asynchronous
#   processing.
#
#srmLsRequestSwitchToAsynchronousModeDelay=infinity

#
#   The following variable enables logging of the history of the SRM
#   request transitions in the database so that it can be examined
#   though the srmWatch monitoring tool.
#srmJdbcMonitoringLogEnabled=false
#
#   Enabling the following option turns off the latest changes that
#   made service to honor the SRM client's protocol list order for
#   GET/PUT commands.  This is needed temporarily to support old
#   srmcp clients.
#srmIgnoreClientProtocolOrder=false

#  ---- SRM Password file.
#
#  Set the following variable to /root/.pgpass for improved security.
#
srmPasswordFile=

#  -- Enable overwrite for SRM v1.1.
#
#   Set the following variable to true if you want overwrite to be
#   enabled for the SRM v1.1 interface as well as for SRM v2.2
#   interface when client does not specify desired overwrite mode.
#   This option will be considered only if the overwriteEnabled
#   variable is set to yes (or true).
#
# srmOverwriteByDefault=false

# ----  Enable custom address resolution.
#
#   The srmCustomGetHostByAddr option enables a custom IP resolution,
#   if the standard InetAddress method fails.
#
# srmCustomGetHostByAddr=false

# --srmClientDNSLookup
# perform the lookup of the client hostname on basis of client ip
# the result is used in pool pool selection
# if srmClientDNSLookup is set to false (default)
# client ip is used
# srmClientDNSLookup=false


#  ---- Enable automatic creation of directories.
#
#  Allow automatic creation of directories via SRM
#
#  allow=true, disallow=false
#
RecursiveDirectoryCreation=true

#  ---- Allow delete via SRM
#
#  Allow deletion of files via the SRM interface.
#
#  allow=true, disallow=false
#
AdvisoryDelete=true

#spaceManagerDatabaseHost=${srmDbHost}


# ---- Reserve space for non SRM transfers.
#
#   If the transfer request comes from the door and there was no
#   prior space reservation made for this file, should we try to
#   reserve space before satisfying the request?
#
#SpaceManagerReserveSpaceForNonSRMTransfers=false


# ---- Location of LinkGroupAuthorizationFile
#
#   The LinkGroupAuthorizationFileName file contains the list of VOMS
#   FQANs that are allowed to make space reservations within a given
#   link group.
#
#SpaceManagerLinkGroupAuthorizationFileName=/opt/d-cache/etc/LinkGroupAuthorization.conf


# --- Default access latency used if space reservation request
#     does not specify one
#
#DefaultAccessLatencyForSpaceReservation=${DefaultAccessLatency}


# if the srm is restarted and there are pending requests
# their state will change to Failed or Done
# if srmCleanPendingRequestsOnRestart is true
#srmCleanPendingRequestsOnRestart=false



#  -----------------------------------------------------------------------
#       Billing / Accounting
#  -----------------------------------------------------------------------

#  ---- Directory for billing logs
#
#   The directory within which the billing logs are to be written.
#
billingDb=${dcache.paths.billing}
#   EXPERT: Uncomment to disable billing into the plain files
#billingDisableTxt=-noTXT

#  ---- Store billing data in database
#
#   This variable describes whether the billing information should be
#   written to a PostgreSQL database.  A database called 'billing' must
#   be created.
#
#billingToDb=no

#   The PostgreSQL database host:
#   EXPERT: First is default if billingToDb=no, second for billingToDb=yes

#billingDatabaseHost=localhost
#billingDbUser=srmdcache
#billingDbPass=srmdcache
#billingDbName=billing
#billingDbCommitRows=100
#billingDbCommitIntervalInMilliseconds=30000

# the following enables using pgfile, which is disabled by default
#billingDbPgPassFileName=/root/.pgpass





#  ------------------------------------------------------------------------
#       Info-based info provider
#  ------------------------------------------------------------------------
#
#   The following variables are used by the script that generates
#   LDIF-formatted data from the XML data the info service provides.
#   This requires both the info service and the internal dCache web
#   service to be running.  The web service must be accessible from
#   whichever machine the info provider is executed on.

#  ---- Host that is running the web service
#
#   The name of the machine that is running the dCache web service.
#   This is used to build the URI for fetching dCache's current
#   state.  If no value is used, localhost is used as a default
#   value.
#
#httpHost=localhost

#  ---- TCP port used by web service
#
#   The TCP port on which the web service listens.  If no value
#   is specified then 2288 is used as a default.
#
httpPort=2288

#  ---- Directory of LDAP transformation configuration
#
#   This variable describes in which directory the configuration file
#   is stored.  The default value is $dcache.paths.etc
#
xylophoneConfigurationDir=${dcache.paths.etc}

#  ---- Filename of LDAP transformation configuration
#
#   This variable provides the filename that describes how the XML
#   should be transformed.  The default value is glue-1.3.xml
#
xylophoneConfigurationFile=glue-1.3.xml

#  ---- XSLT processor
#
#   This variable describes which XSLT processor to use.  The current
#   valid options are xsltproc and saxon.  If none is specified then
#   saxon is used by default.
#
xsltProcessor=saxon

xylophoneXSLTDir=${dcache.paths.share}/xml/xylophone
saxonDir=${dcache.paths.classes}/saxon

# ------------------------------------------------------------------------
#    Statistics module
# ------------------------------------------------------------------------

#  ---- Directory for storing statistics.
#
#   This is the directory under which the statistics module will
#   store historic data.
#
statisticsLocation=${dcache.paths.statistics}


#  -----------------------------------------------------------------------
#       Tape protection
#  -----------------------------------------------------------------------
#
#   The    tape   protection    feature   is    only    available   if
#   stageConfigurationFilePath  line is  uncommented, and  there  is a
#   similarly  named file  containing a  list of  FQANs and  DNs whose
#   owners are allowed to stage files (i.e., to read files from dCache
#   that are stored only on tape).
#
#   Stage configuration can  be provided either on the  door or on the
#   PoolManager as described in the following two cases below:
#
#      1) stage configuration provided on the door
#         (remember to repeat the same configuration on each door):
#         stagePolicyEnforcementPoint=doors
#      2) stage configuration provided on the PoolManager:
#         stagePolicyEnforcementPoint=PoolManager
#
#       The default case is 1).
#
#stageConfigurationFilePath=${dcache.paths.config}/StageConfiguration.conf
#stagePolicyEnforcementPoint=doors
